{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task2_qml.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjrrxGqyIDCH",
        "outputId": "57dad814-641a-4373-a5d5-cff73bc845e7"
      },
      "source": [
        "!pip install PennyLane"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PennyLane in /usr/local/lib/python3.7/dist-packages (0.17.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from PennyLane) (0.10.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from PennyLane) (1.4.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.7/dist-packages (from PennyLane) (1.3)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from PennyLane) (1.4.4)\n",
            "Requirement already satisfied: semantic-version==2.6 in /usr/local/lib/python3.7/dist-packages (from PennyLane) (2.6.0)\n",
            "Requirement already satisfied: autoray in /usr/local/lib/python3.7/dist-packages (from PennyLane) (0.2.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from PennyLane) (2.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from PennyLane) (1.19.5)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd->PennyLane) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVRSy7JnHTf7"
      },
      "source": [
        "# import libraries\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.optimize import NesterovMomentumOptimizer"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRyl7xQCHZS_"
      },
      "source": [
        "# Create a 4-qubit circuit\n",
        "dev = qml.device(\"default.qubit\", wires=4)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72QvSHNaHhmY"
      },
      "source": [
        "# Create the hidden layers using rotation gates and CNOT gates to train the model.\n",
        "def layer(W):\n",
        "\n",
        "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0) \n",
        "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
        "    qml.Rot(W[2, 0], W[2, 1], W[2, 2], wires=2)\n",
        "    qml.Rot(W[3, 0], W[3, 1], W[3, 2], wires=3)\n",
        "\n",
        "    # Using the CNOT gates to make the 4 qubits fully entangled.\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "    qml.CNOT(wires=[0, 2])\n",
        "    qml.CNOT(wires=[1, 2])\n",
        "    qml.CNOT(wires=[1, 3])\n",
        "    qml.CNOT(wires=[2, 3])\n",
        "    qml.CNOT(wires=[3, 0])"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZYNXccxh-S6"
      },
      "source": [
        "# Create Pauli strings for stabilizer states |0011>, |1010>, |0101>, |1100>.\n",
        "obs_1 = qml.Identity(0) @ qml.Identity(1) @ qml.Identity(2) @ qml.Identity(3) # iiii\n",
        "obs_2 = qml.PauliZ(0) @ qml.Identity(1) @ qml.Identity(2) @ qml.Identity(3) # ziii\n",
        "obs_3 = qml.Identity(0) @ qml.PauliZ(1) @ qml.Identity(2) @ qml.Identity(3) # izii\n",
        "obs_4 = qml.Identity(0) @ qml.Identity(1) @ qml.PauliZ(2) @ qml.Identity(3) # iizi\n",
        "obs_5 = qml.Identity(0) @ qml.Identity(1) @ qml.Identity(2) @ qml.PauliZ(3)# iiiz\n",
        "obs_6 = qml.PauliZ(0) @ qml.PauliZ(1) @ qml.Identity(2) @ qml.Identity(3) # zzii\n",
        "obs_7 = qml.PauliZ(0) @ qml.Identity(1) @ qml.PauliZ(2) @ qml.Identity(3) # zizi\n",
        "obs_8 = qml.PauliZ(0) @ qml.Identity(1) @ qml.Identity(2) @ qml.PauliZ(3) # ziiz\n",
        "obs_9 = qml.PauliZ(0) @ qml.PauliZ(1) @ qml.PauliZ(2) @ qml.Identity(3) # zzzi\n",
        "obs_10 = qml.PauliZ(0) @ qml.Identity(1) @ qml.PauliZ(2) @ qml.PauliZ(3) # zizz\n",
        "obs_11 = qml.PauliZ(0) @ qml.PauliZ(1) @ qml.Identity(2) @ qml.PauliZ(3) # zziz\n",
        "obs_12 = qml.Identity(0) @ qml.PauliZ(1) @ qml.PauliZ(2) @ qml.PauliZ(3) # izzz\n",
        "obs_13 = qml.Identity(0) @ qml.PauliZ(1) @ qml.Identity(2) @ qml.PauliZ(3) # iziz\n",
        "obs_14 = qml.Identity(0) @ qml.Identity(1) @ qml.PauliZ(2) @ qml.PauliZ(3) # iizz\n",
        "obs_15 = qml.Identity(0) @ qml.PauliZ(1) @ qml.PauliZ(2) @ qml.Identity(3) # izzi\n",
        "obs_16 = qml.PauliZ(0) @ qml.PauliZ(1) @ qml.PauliZ(2) @ qml.PauliZ(3) # zzzz\n",
        "\n",
        "# The specific states to return given by the task.\n",
        "output = [[0,0,1,1], [1,0,1,0], [0,1,0,1], [1,1,0,0]] \n",
        "\n",
        "# The signs of the Pauli strings.\n",
        "# out1 is the sign of the Pauli string for the stabilizer state |0011>.\n",
        "out1 = [1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, 1, -1, 1]\n",
        "out1 = list(np.array(out1)/16)\n",
        "\n",
        "# out2 is the sign of the Pauli string for the stabilizer state |1010>.\n",
        "out2 =[1, -1, 1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, -1, -1, 1]\n",
        "out2 = list(np.array(out2)/16)\n",
        "\n",
        "# out3 is the sign of the Pauli string for the stabilizer state |0101>.\n",
        "out3 = [1, 1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 1, 1, -1, -1, 1]\n",
        "out3 = list(np.array(out3)/16)\n",
        "\n",
        "# out4 is the sign of the Pauli string for the stabilizer state |1100>.\n",
        "out4 = [1, -1, -1, 1, 1, 1, -1, -1, 1, -1, 1, -1, -1, 1, -1, 1]\n",
        "out4 = list(np.array(out4)/16)\n",
        "\n",
        "# The list of the Pauli strings. \n",
        "obs_list = [obs_1, obs_2, obs_3, obs_4, obs_5, obs_6, obs_7, obs_8, obs_9, obs_10, obs_11, obs_12, obs_13, obs_14, obs_15, obs_16]\n",
        "\n",
        "\n",
        "H_total_1 = qml.Hamiltonian(out1, obs_list)\n",
        "H_total_2 = qml.Hamiltonian(out2, obs_list)\n",
        "H_total_3 = qml.Hamiltonian(out3, obs_list)\n",
        "H_total_4 = qml.Hamiltonian(out4, obs_list)\n"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffxr8bCIHiTp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "5c49a871-9ccd-47e0-db84-be548d1f6dfe"
      },
      "source": [
        "# Prepare initial input states\n",
        "def statepreparation(x):\n",
        "    qml.BasisState(x, wires=[0, 1, 2, 3])\n",
        "print(qml.BasisState(x, wires=[0, 1, 2, 3]))"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-208-f56314267db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstatepreparation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasisState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasisState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-b2YNEpIUjq"
      },
      "source": [
        "# Create the quntum variational circuit.\n",
        "@qml.qnode(dev)\n",
        "def circuit(weights, x, X_encode):\n",
        "    statepreparation(x)\n",
        "    for W in weights:\n",
        "      layer(W)\n",
        "\n",
        "    # binary to decimal number\n",
        "    dec_var=x[0]*(2**3)+x[1]*(2**2)+x[2]*(2**1)+x[3]\n",
        "    \n",
        "    # Assign different input generated randomly to specific output given by the task.\n",
        "    if dec_var == X_encode[0]:\n",
        "      return qml.expval(H_total_1)\n",
        "    elif dec_var == X_encode[1]:\n",
        "      return qml.expval(H_total_2)\n",
        "    elif dec_var == X_encode[2]:\n",
        "      return qml.expval(H_total_3)\n",
        "    elif dec_var == X_encode[3]:\n",
        "      return qml.expval(H_total_4)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqny_0hNIXKu"
      },
      "source": [
        "# Return the results from the quantum variational circuit\n",
        "def variational_classifier(var, x, X_encode):\n",
        "    weights = var[0]\n",
        "    return circuit(weights, x, X_encode) "
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUzmZd6CIavZ"
      },
      "source": [
        "# Loss function loss = loss + abs(l - p), where l is label and p is fidelity. \n",
        "# Use the absolute loss function to rapidly converge the loss.\n",
        "def abs_loss(labels, fidelity):\n",
        "    loss = 0\n",
        "    for l, f in zip(labels, fidelity):\n",
        "        loss = loss + abs(l - f) \n",
        "    loss = loss / len(labels)\n",
        "    return loss"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcPs5we8Idef"
      },
      "source": [
        "# Use the average fidelity as the evaluation metrics for the model. \n",
        "def avg_fidelity(labels, fidelity):\n",
        "    loss = 0\n",
        "    fidelity = sum(fidelity)/4\n",
        "    return fidelity"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrqfoCEiIfjY"
      },
      "source": [
        "# Use the fidelity as the cost function.\n",
        "def cost(var, X, Y, X_encode):\n",
        "    fidelity = [variational_classifier(var, x, X_encode) for x in X]\n",
        "    return abs_loss(Y, fidelity)"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz-6Lu-zIhWF",
        "outputId": "1c323a3b-ae14-4c08-c6ba-8aafab9e23df"
      },
      "source": [
        "from random import random\n",
        "# Generate random states as the inputs for the quantum variational circuit.\n",
        "X_random = [[random(),random(),random(),random()],[random(),random(),random(),random()],[random(),random(),random(),random()],[random(),random(),random(),random()]]\n",
        "for i in range(4):\n",
        "  for j in range(4):\n",
        "    if X_random[i][j] < 0.5:\n",
        "      X_random[i][j] = 0\n",
        "    else:\n",
        "      X_random[i][j] = 1\n",
        "\n",
        "X = X_random\n",
        "\n",
        "# binary to decimal \n",
        "X_encode = [[X_random[0][0]*(2**3)+X_random[0][1]*(2**2)+X_random[0][2]*(2**1)+X_random[0][3]],[X_random[1][0]*(2**3)+X_random[1][1]*(2**2)+X_random[1][2]*(2**1)+X_random[1][3]],[X_random[2][0]*(2**3)+X_random[2][1]*(2**2)+X_random[2][2]*(2**1)+X_random[2][3]],[X_random[3][0]*(2**3)+X_random[3][1]*(2**2)+X_random[3][2]*(2**1)+X_random[3][3]]]\n",
        "\n",
        "# If the states duplicated, generate a new set of random states. \n",
        "while set([x for x in X_encode if X_encode.count(x) > 1]):\n",
        "  X_random = [[random(),random(),random(),random()],[random(),random(),random(),random()],[random(),random(),random(),random()],[random(),random(),random(),random()]]\n",
        "  for i in range(4):\n",
        "    for j in range(4):\n",
        "      if X_random[i][j] < 0.5:\n",
        "        X_random[i][j] = 0\n",
        "      else:\n",
        "        X_random[i][j] = 1\n",
        "\n",
        "  X = X_random\n",
        "  X_encode = [[X_random[0][0]*(2**3)+X_random[0][1]*(2**2)+X_random[0][2]*(2**1)+X_random[0][3]],[X_random[1][0]*(2**3)+X_random[1][1]*(2**2)+X_random[1][2]*(2**1)+X_random[1][3]],[X_random[2][0]*(2**3)+X_random[2][1]*(2**2)+X_random[2][2]*(2**1)+X_random[2][3]],[X_random[3][0]*(2**3)+X_random[3][1]*(2**2)+X_random[3][2]*(2**1)+X_random[3][3]]]\n",
        "\n",
        "print(\"X_random:\", X_random)\n",
        "\n",
        "# Label the fidelity of the specific outputs given by the task to be 1. \n",
        "Y = [1,1,1,1]"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_random: [[0, 1, 1, 0], [1, 1, 0, 0], [0, 0, 0, 1], [0, 1, 1, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgqHT14SIjXh",
        "outputId": "c391df02-bf30-4871-f7a0-e0209a97bb49"
      },
      "source": [
        "# Setup the initial variable\n",
        "np.random.seed(0)\n",
        "num_qubits = 4 # Number of the qubits used in the quantum variational circuit\n",
        "num_layers = 8 # Number of the hidden layers.\n",
        "var_init = (0.01 * np.random.randn(num_layers, num_qubits, 3), 0.0) \n",
        "print(var_init)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[ 0.01764052,  0.00400157,  0.00978738],\n",
            "         [ 0.02240893,  0.01867558, -0.00977278],\n",
            "         [ 0.00950088, -0.00151357, -0.00103219],\n",
            "         [ 0.00410599,  0.00144044,  0.01454274]],\n",
            "\n",
            "        [[ 0.00761038,  0.00121675,  0.00443863],\n",
            "         [ 0.00333674,  0.01494079, -0.00205158],\n",
            "         [ 0.00313068, -0.00854096, -0.0255299 ],\n",
            "         [ 0.00653619,  0.00864436, -0.00742165]],\n",
            "\n",
            "        [[ 0.02269755, -0.01454366,  0.00045759],\n",
            "         [-0.00187184,  0.01532779,  0.01469359],\n",
            "         [ 0.00154947,  0.00378163, -0.00887786],\n",
            "         [-0.01980796, -0.00347912,  0.00156349]],\n",
            "\n",
            "        [[ 0.01230291,  0.0120238 , -0.00387327],\n",
            "         [-0.00302303, -0.01048553, -0.01420018],\n",
            "         [-0.0170627 ,  0.01950775, -0.00509652],\n",
            "         [-0.00438074, -0.01252795,  0.0077749 ]],\n",
            "\n",
            "        [[-0.01613898, -0.0021274 , -0.00895467],\n",
            "         [ 0.00386902, -0.00510805, -0.01180632],\n",
            "         [-0.00028182,  0.00428332,  0.00066517],\n",
            "         [ 0.00302472, -0.00634322, -0.00362741]],\n",
            "\n",
            "        [[-0.0067246 , -0.00359553, -0.00813146],\n",
            "         [-0.01726283,  0.00177426, -0.00401781],\n",
            "         [-0.01630198,  0.00462782, -0.00907298],\n",
            "         [ 0.00051945,  0.00729091,  0.00128983]],\n",
            "\n",
            "        [[ 0.01139401, -0.01234826,  0.00402342],\n",
            "         [-0.0068481 , -0.00870797, -0.0057885 ],\n",
            "         [-0.00311553,  0.00056165, -0.0116515 ],\n",
            "         [ 0.00900826,  0.00465662, -0.01536244]],\n",
            "\n",
            "        [[ 0.01488252,  0.01895889,  0.0117878 ],\n",
            "         [-0.00179925, -0.01070753,  0.01054452],\n",
            "         [-0.00403177,  0.01222445,  0.00208275],\n",
            "         [ 0.00976639,  0.00356366,  0.00706573]]], requires_grad=True), 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk4xpJZ2ImGE"
      },
      "source": [
        "# Optimizer for the model (Ref: https://pennylane.readthedocs.io/en/stable/code/api/pennylane.NesterovMomentumOptimizer.html)\n",
        "opt = NesterovMomentumOptimizer(0.5) \n",
        "# batch size \n",
        "batch_size = 8"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30h445coItE4",
        "outputId": "2d522d4f-ba01-43e7-8758-4ab849799b3d"
      },
      "source": [
        "var = var_init # Variables of the rotation gates at the hidden layers\n",
        "\n",
        "# Training process\n",
        "for it in range(100):\n",
        "    # Update the weights by one optimizer step\n",
        "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
        "    X_batch = np.array(X)[batch_index.astype(int)]\n",
        "    Y_batch = np.array(Y)[batch_index.astype(int)]\n",
        "    var = opt.step(lambda v: cost(v, X_batch, Y_batch, X_encode), var)\n",
        "    # Compute accuracy\n",
        "    fidelity = [variational_classifier(var, x, X_encode) for x in X]\n",
        "    print(fidelity)\n",
        "    acc = avg_fidelity(Y, fidelity)\n",
        "\n",
        "    print(\n",
        "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
        "            it + 1, cost(var, X, Y, X_encode), acc\n",
        "        )\n",
        "    )"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5.22432438611331e-06, 0.9997756262823823, 9.578368165646944e-06, 1.0625389738436186e-05]\n",
            "Iter:     1 | Cost: 0.7500497 | Accuracy: 0.2499503 \n",
            "[3.939118800484753e-06, 0.999918854556334, 9.638485553797871e-06, 1.0453482527719715e-05]\n",
            "Iter:     2 | Cost: 0.7500143 | Accuracy: 0.2499857 \n",
            "[3.2975146444652603e-06, 0.9999757472893547, 1.1037300883198764e-05, 1.1672858684405596e-05]\n",
            "Iter:     3 | Cost: 0.7499996 | Accuracy: 0.2500004 \n",
            "[1.8366513531917206e-06, 0.9999714336604906, 1.5734891397792272e-05, 1.6289356777970943e-05]\n",
            "Iter:     4 | Cost: 0.7499987 | Accuracy: 0.2500013 \n",
            "[1.1155202870039016e-06, 0.9999291733966993, 2.9164486594818184e-05, 2.971449352322242e-05]\n",
            "Iter:     5 | Cost: 0.7500027 | Accuracy: 0.2499973 \n",
            "[6.866673254862787e-07, 0.9998168816981094, 9.249231644087308e-05, 9.316089276409367e-05]\n",
            "Iter:     6 | Cost: 0.7499992 | Accuracy: 0.2500008 \n",
            "[4.41125274704135e-07, 0.9996849102335734, 0.00020304069107367206, 0.00020397382432094102]\n",
            "Iter:     7 | Cost: 0.7499769 | Accuracy: 0.2500231 \n",
            "[2.699005065831539e-07, 0.9994707968042977, 0.00042917186922922235, 0.00043090301197633296]\n",
            "Iter:     8 | Cost: 0.7499172 | Accuracy: 0.2500828 \n",
            "[1.1436547998899815e-07, 0.9988314873447904, 0.0011000376829561898, 0.0011040933793616536]\n",
            "Iter:     9 | Cost: 0.7497411 | Accuracy: 0.2502589 \n",
            "[2.483441352563176e-08, 0.9982423270717713, 0.0017317900283655707, 0.0017393032750020881]\n",
            "Iter:    10 | Cost: 0.7495716 | Accuracy: 0.2504284 \n",
            "[4.361336014557793e-10, 0.9958255181148351, 0.004167275429459119, 0.004182554329851068]\n",
            "Iter:    11 | Cost: 0.7489562 | Accuracy: 0.2510438 \n",
            "[1.0039331199696022e-08, 0.9908246326518557, 0.009168359341604093, 0.009196978164330447]\n",
            "Iter:    12 | Cost: 0.7477025 | Accuracy: 0.2522975 \n",
            "[1.9534296083478786e-08, 0.9882161937746506, 0.011775943131898642, 0.011808574046876102]\n",
            "Iter:    13 | Cost: 0.7470498 | Accuracy: 0.2529502 \n",
            "[3.1321115603888394e-08, 0.9797881513353334, 0.020199006641865885, 0.02024227057278767]\n",
            "Iter:    14 | Cost: 0.7449426 | Accuracy: 0.2550574 \n",
            "[3.2116172450635805e-08, 0.9770973052470686, 0.022900037535670006, 0.022937902119296374]\n",
            "Iter:    15 | Cost: 0.7442662 | Accuracy: 0.2557338 \n",
            "[5.153973642313403e-08, 0.9679657791426168, 0.03203821111010727, 0.03208063698676354]\n",
            "Iter:    16 | Cost: 0.7419788 | Accuracy: 0.2580212 \n",
            "[4.9482490813157476e-08, 0.9423120025785965, 0.057703629561737524, 0.05776385519946521]\n",
            "Iter:    17 | Cost: 0.7355551 | Accuracy: 0.2644449 \n",
            "[3.6712177527153944e-08, 0.9406349973876582, 0.059428798831392377, 0.05947168410405171]\n",
            "Iter:    18 | Cost: 0.7351161 | Accuracy: 0.2648839 \n",
            "[2.3195742292203558e-08, 0.952592907449992, 0.047516625494831266, 0.04754313820688867]\n",
            "Iter:    19 | Cost: 0.7380868 | Accuracy: 0.2619132 \n",
            "[1.137236811665776e-08, 0.9420097354869508, 0.058177565349904536, 0.058212932606617335]\n",
            "Iter:    20 | Cost: 0.7353999 | Accuracy: 0.2646001 \n",
            "[9.258666777700597e-09, 0.90586975760373, 0.09452344041315336, 0.09459243184970607]\n",
            "Iter:    21 | Cost: 0.7262536 | Accuracy: 0.2737464 \n",
            "[1.767262894358801e-08, 0.8810172099974733, 0.11994698039191426, 0.12002878923834728]\n",
            "Iter:    22 | Cost: 0.7197518 | Accuracy: 0.2802482 \n",
            "[4.450998800087369e-08, 0.8569982935612832, 0.1455752353539022, 0.1456426706614679]\n",
            "Iter:    23 | Cost: 0.7129459 | Accuracy: 0.2870541 \n",
            "[1.1338723100023929e-07, 0.7608562864361545, 0.24627893653566427, 0.24634342193007208]\n",
            "Iter:    24 | Cost: 0.6866303 | Accuracy: 0.3133697 \n",
            "[2.15321035841598e-07, 0.5560576735701734, 0.46908331452033625, 0.4694956285399649]\n",
            "Iter:    25 | Cost: 0.6263408 | Accuracy: 0.3736592 \n",
            "[2.5440687019540054e-07, 0.32132303801496265, 0.7816131462965202, 0.7827196662483422]\n",
            "Iter:    26 | Cost: 0.5285860 | Accuracy: 0.4714140 \n",
            "[6.172850898766846e-07, 0.4067465703427505, 0.9659314592535279, 0.9695993923582538]\n",
            "Iter:    27 | Cost: 0.4144305 | Accuracy: 0.5855695 \n",
            "[1.862719298723059e-06, 0.815570681412662, 0.9911661253756883, 0.9841484471459107]\n",
            "Iter:    28 | Cost: 0.3022782 | Accuracy: 0.6977218 \n",
            "[2.857274054690606e-06, 0.9985559561121212, 0.9502497114160245, 0.9488801710308874]\n",
            "Iter:    29 | Cost: 0.2755778 | Accuracy: 0.7244222 \n",
            "[2.7216767043772294e-06, 0.9998035991601841, 0.9116439608626057, 0.9124890078588754]\n",
            "Iter:    30 | Cost: 0.2940152 | Accuracy: 0.7059848 \n",
            "[3.0169518209707813e-06, 0.9987009000796697, 0.9221715165961055, 0.9214920471549031]\n",
            "Iter:    31 | Cost: 0.2894081 | Accuracy: 0.7105919 \n",
            "[2.439652075574006e-06, 0.9996215582650672, 0.964791128390238, 0.9648754842374501]\n",
            "Iter:    32 | Cost: 0.2676773 | Accuracy: 0.7323227 \n",
            "[2.101861063710797e-06, 0.9984862383143227, 0.994749958372843, 0.9947789980207971]\n",
            "Iter:    33 | Cost: 0.2529957 | Accuracy: 0.7470043 \n",
            "[1.6376490316397097e-06, 0.9997011573929271, 0.9993008089561773, 0.9992809162863309]\n",
            "Iter:    34 | Cost: 0.2504289 | Accuracy: 0.7495711 \n",
            "[1.3015743074093478e-06, 0.9988722145574909, 0.9939849007939718, 0.9939614167488908]\n",
            "Iter:    35 | Cost: 0.2532950 | Accuracy: 0.7467050 \n",
            "[8.444775163249374e-07, 0.9998188533624842, 0.9911697265561619, 0.9909656955584486]\n",
            "Iter:    36 | Cost: 0.2545112 | Accuracy: 0.7454888 \n",
            "[6.374437660425225e-07, 0.9992006129882687, 0.9909549315402595, 0.9907788683838759]\n",
            "Iter:    37 | Cost: 0.2547662 | Accuracy: 0.7452338 \n",
            "[5.150964737937747e-07, 0.9999520127466668, 0.9947543307588, 0.9946700797412552]\n",
            "Iter:    38 | Cost: 0.2526558 | Accuracy: 0.7473442 \n",
            "[4.368461204093399e-07, 0.9999668074504994, 0.9981975987314411, 0.997996061698448]\n",
            "Iter:    39 | Cost: 0.2509598 | Accuracy: 0.7490402 \n",
            "[4.151418774023252e-07, 0.9999708730359771, 0.999825552814557, 0.9997152011218543]\n",
            "Iter:    40 | Cost: 0.2501220 | Accuracy: 0.7498780 \n",
            "[3.965481290071904e-07, 0.9999775987083266, 0.9998104434062443, 0.9998135546534705]\n",
            "Iter:    41 | Cost: 0.2500995 | Accuracy: 0.7499005 \n",
            "[3.869736983769245e-07, 0.9999870773533851, 0.9994944325828236, 0.9994442969755727]\n",
            "Iter:    42 | Cost: 0.2502685 | Accuracy: 0.7497315 \n",
            "[4.0043502200215464e-07, 0.9999880994593462, 0.9992711104963572, 0.9992346130080063]\n",
            "Iter:    43 | Cost: 0.2503764 | Accuracy: 0.7496236 \n",
            "[4.1947869827002604e-07, 0.9999898472722424, 0.9993623766964228, 0.9993472613859684]\n",
            "Iter:    44 | Cost: 0.2503250 | Accuracy: 0.7496750 \n",
            "[4.900753437162009e-07, 0.9999860669207469, 0.9995618436353573, 0.9995608001049364]\n",
            "Iter:    45 | Cost: 0.2502227 | Accuracy: 0.7497773 \n",
            "[5.855941969876155e-07, 0.999979928539755, 0.9998809638745161, 0.9998749651086205]\n",
            "Iter:    46 | Cost: 0.2500659 | Accuracy: 0.7499341 \n",
            "[6.891871142458705e-07, 0.9999865480536598, 0.9999883057557243, 0.9999800070421576]\n",
            "Iter:    47 | Cost: 0.2500111 | Accuracy: 0.7499889 \n",
            "[7.723291600564286e-07, 0.9999895779778012, 0.9999555596855123, 0.9999548949241388]\n",
            "Iter:    48 | Cost: 0.2500248 | Accuracy: 0.7499752 \n",
            "[8.748199566283033e-07, 0.9999928707490991, 0.9998994956365885, 0.9998987982145534]\n",
            "Iter:    49 | Cost: 0.2500520 | Accuracy: 0.7499480 \n",
            "[9.445834885379867e-07, 0.9999946083944592, 0.999897592306723, 0.9998967143330479]\n",
            "Iter:    50 | Cost: 0.2500525 | Accuracy: 0.7499475 \n",
            "[1.088698885827466e-06, 0.9999955284303274, 0.9999180071146991, 0.9999170944796458]\n",
            "Iter:    51 | Cost: 0.2500421 | Accuracy: 0.7499579 \n",
            "[9.448405907455659e-07, 0.9999966636902399, 0.9999476016558146, 0.9999465843249373]\n",
            "Iter:    52 | Cost: 0.2500271 | Accuracy: 0.7499729 \n",
            "[8.293543581616714e-07, 0.9999965914053356, 0.9999815158162746, 0.9999807704421617]\n",
            "Iter:    53 | Cost: 0.2500101 | Accuracy: 0.7499899 \n",
            "[7.442073304692043e-07, 0.9999961155517257, 0.9999936794154507, 0.9999930206356769]\n",
            "Iter:    54 | Cost: 0.2500041 | Accuracy: 0.7499959 \n",
            "[6.077668987317097e-07, 0.9999964915230748, 0.9999907485501467, 0.9999903298856792]\n",
            "Iter:    55 | Cost: 0.2500055 | Accuracy: 0.7499945 \n",
            "[5.364389559017746e-07, 0.9999968508476597, 0.9999865403383934, 0.9999863617614283]\n",
            "Iter:    56 | Cost: 0.2500074 | Accuracy: 0.7499926 \n",
            "[4.886077657403898e-07, 0.9999968183811674, 0.9999908291990823, 0.9999907153250112]\n",
            "Iter:    57 | Cost: 0.2500053 | Accuracy: 0.7499947 \n",
            "[4.47065427372495e-07, 0.9999972741775195, 0.999994547220027, 0.999994460410051]\n",
            "Iter:    58 | Cost: 0.2500033 | Accuracy: 0.7499967 \n",
            "[3.760900940050216e-07, 0.9999983792877953, 0.9999958051894979, 0.9999956823078758]\n",
            "Iter:    59 | Cost: 0.2500024 | Accuracy: 0.7499976 \n",
            "[3.289301691716817e-07, 0.9999988248594283, 0.9999957548682397, 0.9999956226589454]\n",
            "Iter:    60 | Cost: 0.2500024 | Accuracy: 0.7499976 \n",
            "[2.909088611391386e-07, 0.9999990996390634, 0.99999542368261, 0.9999952758302754]\n",
            "Iter:    61 | Cost: 0.2500025 | Accuracy: 0.7499975 \n",
            "[2.646565638933507e-07, 0.999998789550254, 0.9999964383178735, 0.9999963233247406]\n",
            "Iter:    62 | Cost: 0.2500020 | Accuracy: 0.7499980 \n",
            "[2.531888118398329e-07, 0.9999983930252389, 0.9999972356015157, 0.9999971510458745]\n",
            "Iter:    63 | Cost: 0.2500017 | Accuracy: 0.7499983 \n",
            "[2.646795502075916e-07, 0.9999982307968167, 0.9999975650285029, 0.9999974948544188]\n",
            "Iter:    64 | Cost: 0.2500016 | Accuracy: 0.7499984 \n",
            "[2.6170109019424403e-07, 0.9999986453154075, 0.999997752645475, 0.9999976924750489]\n",
            "Iter:    65 | Cost: 0.2500014 | Accuracy: 0.7499986 \n",
            "[2.531850563716742e-07, 0.9999989063257051, 0.9999979096919621, 0.9999978575019632]\n",
            "Iter:    66 | Cost: 0.2500013 | Accuracy: 0.7499987 \n",
            "[2.341039143996526e-07, 0.9999991326659015, 0.9999980974039443, 0.9999980469862366]\n",
            "Iter:    67 | Cost: 0.2500011 | Accuracy: 0.7499989 \n",
            "[2.1624952867976832e-07, 0.9999992558102615, 0.9999983427382809, 0.9999982911550291]\n",
            "Iter:    68 | Cost: 0.2500010 | Accuracy: 0.7499990 \n",
            "[2.094215701201052e-07, 0.9999993595905214, 0.9999985322035592, 0.9999984756059949]\n",
            "Iter:    69 | Cost: 0.2500009 | Accuracy: 0.7499991 \n",
            "[2.0702724429222386e-07, 0.9999993680393439, 0.9999987283280486, 0.9999986709523789]\n",
            "Iter:    70 | Cost: 0.2500008 | Accuracy: 0.7499992 \n",
            "[2.0468260476802502e-07, 0.999999392060362, 0.9999988689928614, 0.9999988134567694]\n",
            "Iter:    71 | Cost: 0.2500007 | Accuracy: 0.7499993 \n",
            "[1.9808194511028443e-07, 0.9999993866142015, 0.9999990084171535, 0.9999989570611051]\n",
            "Iter:    72 | Cost: 0.2500006 | Accuracy: 0.7499994 \n",
            "[1.970991831481972e-07, 0.9999993888316775, 0.9999991277984145, 0.9999990797704649]\n",
            "Iter:    73 | Cost: 0.2500006 | Accuracy: 0.7499994 \n",
            "[1.737014054675745e-07, 0.9999995629740404, 0.9999991928115889, 0.999999143614695]\n",
            "Iter:    74 | Cost: 0.2500005 | Accuracy: 0.7499995 \n",
            "[1.4886977020567294e-07, 0.9999996394499332, 0.9999992813000238, 0.9999992385631911]\n",
            "Iter:    75 | Cost: 0.2500004 | Accuracy: 0.7499996 \n",
            "[1.2294559532943783e-07, 0.9999997485084198, 0.9999993211327174, 0.9999992795511242]\n",
            "Iter:    76 | Cost: 0.2500004 | Accuracy: 0.7499996 \n",
            "[1.040801912086109e-07, 0.9999997922327222, 0.9999994012236074, 0.999999363382211]\n",
            "Iter:    77 | Cost: 0.2500003 | Accuracy: 0.7499997 \n",
            "[9.361135908103613e-08, 0.9999997411874036, 0.9999995258567784, 0.9999994953488748]\n",
            "Iter:    78 | Cost: 0.2500003 | Accuracy: 0.7499997 \n",
            "[8.65964874946501e-08, 0.9999997395437745, 0.9999995924151, 0.9999995696109026]\n",
            "Iter:    79 | Cost: 0.2500003 | Accuracy: 0.7499997 \n",
            "[7.871208058951584e-08, 0.9999998055690689, 0.999999638339299, 0.9999996203903403]\n",
            "Iter:    80 | Cost: 0.2500002 | Accuracy: 0.7499998 \n",
            "[7.35429728018766e-08, 0.9999998426849739, 0.9999996796829603, 0.9999996656700931]\n",
            "Iter:    81 | Cost: 0.2500002 | Accuracy: 0.7499998 \n",
            "[7.003358645091273e-08, 0.9999998752923673, 0.9999997093793442, 0.9999996978307619]\n",
            "Iter:    82 | Cost: 0.2500002 | Accuracy: 0.7499998 \n",
            "[6.133182952478e-08, 0.9999998874848911, 0.9999997576384321, 0.9999997484206975]\n",
            "Iter:    83 | Cost: 0.2500001 | Accuracy: 0.7499999 \n",
            "[5.4006544819573676e-08, 0.9999999030598433, 0.9999997926539697, 0.9999997851605498]\n",
            "Iter:    84 | Cost: 0.2500001 | Accuracy: 0.7499999 \n",
            "[4.830901041003033e-08, 0.9999999026202523, 0.999999831981538, 0.9999998262970808]\n",
            "Iter:    85 | Cost: 0.2500001 | Accuracy: 0.7499999 \n",
            "[4.515394552012664e-08, 0.9999999003485613, 0.9999998610339988, 0.999999856773782]\n",
            "Iter:    86 | Cost: 0.2500001 | Accuracy: 0.7499999 \n",
            "[4.4055815447141544e-08, 0.999999901329395, 0.9999998828823634, 0.999999879773232]\n",
            "Iter:    87 | Cost: 0.2500001 | Accuracy: 0.7499999 \n",
            "[3.965788634291423e-08, 0.999999922636125, 0.9999998987673563, 0.9999998964053671]\n",
            "Iter:    88 | Cost: 0.2500001 | Accuracy: 0.7499999 \n",
            "[3.3691812215130845e-08, 0.9999999364492783, 0.9999999136960327, 0.9999999119063642]\n",
            "Iter:    89 | Cost: 0.2500001 | Accuracy: 0.7499999 \n",
            "[3.0095532746465814e-08, 0.9999999429483998, 0.9999999281124177, 0.9999999266576769]\n",
            "Iter:    90 | Cost: 0.2500000 | Accuracy: 0.7500000 \n",
            "[2.7402205185489414e-08, 0.9999999459448736, 0.999999941319639, 0.9999999400233679]\n",
            "Iter:    91 | Cost: 0.2500000 | Accuracy: 0.7500000 \n",
            "[2.5708165950211193e-08, 0.9999999528524266, 0.9999999502752992, 0.9999999488909739]\n",
            "Iter:    92 | Cost: 0.2500000 | Accuracy: 0.7500000 \n",
            "[2.384512846204112e-08, 0.9999999608777362, 0.9999999566068021, 0.9999999550301871]\n",
            "Iter:    93 | Cost: 0.2500000 | Accuracy: 0.7500000 \n",
            "[2.1573969798127646e-08, 0.999999966271362, 0.999999963428977, 0.9999999616615903]\n",
            "Iter:    94 | Cost: 0.2500000 | Accuracy: 0.7500000 \n",
            "[2.1005592161504882e-08, 0.9999999682956828, 0.9999999696634165, 0.9999999676254094]\n",
            "Iter:    95 | Cost: 0.2500000 | Accuracy: 0.7500000 \n",
            "[2.169237767885024e-08, 0.9999999666148488, 0.9999999754865848, 0.9999999735916894]\n",
            "Iter:    96 | Cost: 0.2500000 | Accuracy: 0.7500000 \n",
            "[2.1389001084171078e-08, 0.9999999664637356, 0.9999999801264465, 0.9999999786756977]\n",
            "Iter:    97 | Cost: 0.2500000 | Accuracy: 0.7500000 \n",
            "[1.990882195906929e-08, 0.9999999684025844, 0.9999999839546506, 0.9999999829227487]\n",
            "Iter:    98 | Cost: 0.2500000 | Accuracy: 0.7500000 \n",
            "[1.928305545101372e-08, 0.9999999705802387, 0.9999999867715947, 0.9999999859720146]\n",
            "Iter:    99 | Cost: 0.2500000 | Accuracy: 0.7500000 \n",
            "[1.7963317194835682e-08, 0.9999999742513079, 0.9999999887718483, 0.9999999881031476]\n",
            "Iter:   100 | Cost: 0.2500000 | Accuracy: 0.7500000 \n"
          ]
        }
      ]
    }
  ]
}